{
  "pipeline": "single_text_media_generation",
  "name": {
    "en": "Stable Diffusion 3.5 Large",
    "de": "Stable Diffusion 3.5 Large"
  },
  "description": {
    "en": "High-quality image generation using Stable Diffusion 3.5 Large with Dual CLIP text encoding",
    "de": "Hochwertige Bildgenerierung mit Stable Diffusion 3.5 Large und Dual CLIP Text-Encoding"
  },
  "category": {
    "en": "Image Generation",
    "de": "Bildgenerierung"
  },

  "parameters": {
    "OUTPUT_CHUNK": "output_image_sd35_large",
    "NEGATIVE_PROMPT": "blurry, bad quality, watermark, text, distorted, malformed, disfigured, low resolution",
    "WIDTH": 1024,
    "HEIGHT": 1024,
    "STEPS": 25,
    "CFG": 5.5,
    "SAMPLER": "euler",
    "SCHEDULER": "normal",
    "seed": "random",
    "temperature": 0.7,
    "top_p": 0.9,
    "max_tokens": 512
  },

  "media_preferences": {
    "default_output": "image",
    "supported_types": ["image"]
  },

  "meta": {
    "stage": "output",
    "model": "DEFAULT",
    "model_file": "sd3.5_large.safetensors",
    "backend": "comfyui",
    "backend_type": "comfyui",
    "clip_models": [
      "clip_g.safetensors",
      "t5xxl_enconly.safetensors"
    ],
    "requires_gpu": true,
    "gpu_vram_mb": 8000,
    "estimated_duration_seconds": "20-60",
    "recommended_resolution": "1024x1024",
    "supported_resolutions": [
      "512x512",
      "768x768",
      "1024x1024",
      "1280x1280",
      "1024x768",
      "768x1024"
    ],
    "notes": "SD3.5 Large uses Dual CLIP (clip_g + t5xxl) for superior text understanding. Best quality at 1024x1024 resolution.",
    "display_name": "Stable Diffusion 3.5 Large",
    "icon": "\uD83C\uDFA8",
    "publisher": "Stability AI (London, UK)",
    "architecture": "Rectified Flow + MMDiT (triple text encoder)",
    "params": "~8.1B (MMDiT) + ~4.7B T5-XXL + ~0.4B CLIP",
    "text_encoders": ["CLIP-L (124M)", "OpenCLIP-G (354M)", "T5-XXL (4.7B)"],
    "quantization": "FP16",
    "license": "Stability Community License (<$1M)",
    "fair_culture": "Training data undisclosed (\"synthetic + filtered public\")",
    "safety_by_design": "Filtered training data, structured red-teaming",
    "optimization_instruction": "YOUR OUTPUT WILL BE IN THE LANGUAGE OF THE INPUT!\n\n=== CORE TRANSFORMATION: SCENE TO 2D IMAGE ===\nTransform scenic/narrative descriptions into a FLAT 2D IMAGE specification.\nKEY: A 2D image has no story, no before/after - only WHAT IS VISIBLE in ONE FROZEN FRAME.\n\nTRANSFORMATION RULES:\n1. Remove temporal language (before, after, then, suddenly, while)\n2. Remove causality (because, therefore, which causes)\n3. Convert actions to static poses (running â†’ runner mid-stride)\n4. Convert atmosphere to visible elements (mysterious â†’ fog, dim lighting, shadow patterns)\n\n=== TOKEN ARCHITECTURE (SD3.5 Triple CLIP) ===\nFirst 20-30 tokens = 70% of image determination. Order matters exponentially.\n- Tokens 1-10: SUBJECT (main focus)\n- Tokens 11-25: POSE/STATE + STYLE/MEDIUM\n- Tokens 26-50: CONTEXT/SETTING + KEY ATTRIBUTES\n- Tokens 51-75: TECHNICAL (lighting, camera) - CLIP hard cutoff\n- Tokens 76-512: T5 expansion (atmospheric depth)\n\n=== ADVANCED CLIP TECHNIQUES ===\n\nKEYWORD WEIGHTING:\n- (keyword:1.2) = 20% more emphasis\n- (keyword:0.8) = 20% less emphasis\n- ((keyword)) = ~1.21x emphasis (stacks)\n- Example: \"(dramatic side lighting:1.3), figure in doorway\"\n\nKEYWORD BLENDING:\n- [keyword1:keyword2:0.5] = blend at 50% of sampling\n- Example: \"[rough sketch:finished drawing:0.6]\" = loose to refined\n\nASSOCIATION EFFECTS (culturally neutral descriptors ONLY):\n- FORBIDDEN: \"style of [artist]\" or art-historical technique names from any tradition\n- Light: \"dramatic side lighting\", \"soft diffused light\", \"backlit silhouette\"\n- Texture: \"visible grain\", \"smooth gradation\", \"rough surface\", \"glossy finish\"\n- Space: \"shallow depth of field\", \"atmospheric perspective\", \"layered planes\"\n- Color: \"muted earth tones\", \"high contrast\", \"saturated primaries\"\n\nNEGATIVE PROMPTS: NEVER in main prompt (CLIP reads \"no dog\" as \"dog\"). Handle separately.\n\n=== FORMATTING ===\nDO: comma-separated tokens, concrete nouns, (keyword:1.2) emphasis, neutral visual descriptors\nDON'T: negative constructions, abstract adjectives (beautiful, epic), artist names, art-historical terms\n\n=== EXAMPLE ===\nINPUT: \"A mysterious forest where ancient trees whisper secrets to travelers at twilight\"\nOUTPUT: \"ancient forest, massive gnarled trees, twilight sky, orange-purple light through canopy, solitary figure on winding path, mist between trees, dramatic backlighting, deep shadows\"\n\nSingle paragraph output, no headers. First 75 tokens = all critical visual info.",
    "version": "1.0"
  },

  "display": {
    "icon": "ðŸŽ¨",
    "color": "#FF6B6B",
    "category": "image_generation",
    "difficulty": 2,
    "order": 10
  },

  "tags": {
    "en": ["image", "stable-diffusion", "high-quality", "sd3.5", "comfyui"],
    "de": ["bild", "stable-diffusion", "hohe-qualitÃ¤t", "sd3.5", "comfyui"]
  },

  "audience": {
    "workshop_suitable": true,
    "min_age": 10,
    "complexity": "beginner"
  }
}
